# utmosv2-exported

> **WARNING: AI-GENERATED CODE**
>
> This entire repository, including all code, documentation, and examples, was generated by AI (Claude). While efforts have been made to ensure correctness, this code has not been extensively tested in production environments. **Use at your own risk.**
>
> If you encounter issues, please report them on the [issue tracker](https://github.com/gibiansky/utmosv2-exported/issues).

## What is this?

This package provides standalone inference for the [UTMOSv2](https://github.com/sarulab-speech/UTMOSv2) speech quality assessment model. UTMOSv2 is a state-of-the-art model for predicting Mean Opinion Scores (MOS) for synthesized speech.

**Key feature:** This package does NOT require HuggingFace `transformers` or `torchvision` at inference time. The wav2vec2 SSL encoder and fusion model are both exported to TorchScript, resulting in minimal dependencies.

### Why does this exist?

The original UTMOSv2 package has heavy dependencies (transformers, torchvision) that can conflict with other packages or significantly increase Docker image sizes. This package provides the same inference capability with only:

- `torch`
- `torchaudio`
- `soundfile`
- `librosa`

## Installation

```bash
pip install git+https://github.com/gibiansky/utmosv2-exported.git
```

Or clone and install locally:

```bash
git clone https://github.com/gibiansky/utmosv2-exported.git
cd utmosv2-exported
pip install -e .
```

## Quick Start

```python
from utmosv2_exported import UTMOSv2Predictor

# Create predictor (downloads models automatically on first use)
predictor = UTMOSv2Predictor()

# Predict MOS score for an audio file
score = predictor.predict("audio.wav")
print(f"MOS score: {score:.2f}")
```

### Command Line

```bash
# Predict MOS for a single file
utmosv2-predict audio.wav

# Predict MOS for multiple files
utmosv2-predict audio1.wav audio2.wav audio3.wav

# Use GPU
utmosv2-predict audio.wav --device cuda
```

## API Reference

### UTMOSv2Predictor

The main class for inference.

```python
class UTMOSv2Predictor:
    def __init__(
        self,
        ssl_model_path: str | Path | None = None,
        fusion_model_path: str | Path | None = None,
        config_path: str | Path | None = None,
        cache_dir: str | Path | None = None,
        device: str = "cpu",
        auto_download: bool = True,
    ):
        """
        Initialize the predictor.

        Args:
            ssl_model_path: Path to SSL TorchScript model. If None, uses cached/downloads.
            fusion_model_path: Path to fusion TorchScript model. If None, uses cached/downloads.
            config_path: Path to config JSON. If None, uses default config.
            cache_dir: Cache directory for models. Uses TORCH_HOME if not set.
            device: Device for inference ("cpu", "cuda", "mps").
            auto_download: If True, download models automatically if not present.
        """
```

#### Methods

```python
def predict(self, audio_path: str | Path, seed: int | None = None) -> float:
    """
    Predict MOS score for an audio file.

    Args:
        audio_path: Path to audio file (WAV, MP3, FLAC, etc.)
        seed: Random seed for reproducible segment selection

    Returns:
        Predicted MOS score (typically 1-5 scale)
    """

def predict_batch(self, audio_paths: list, seed: int | None = None) -> list[float]:
    """
    Predict MOS scores for multiple audio files.

    Args:
        audio_paths: List of paths to audio files
        seed: Base seed. Each file uses seed+index for reproducibility.

    Returns:
        List of predicted MOS scores
    """

def predict_tensor(self, audio: torch.Tensor, seed: int | None = None) -> float:
    """
    Predict MOS score for audio tensor directly.

    Args:
        audio: Audio tensor (samples,) at 16kHz sample rate
        seed: Random seed for reproducible segment selection

    Returns:
        Predicted MOS score
    """
```

## Model Cache

Models are cached using the same conventions as `torch.hub`:

1. `UTMOSV2_CACHE_DIR` environment variable (if set)
2. `TORCH_HOME/hub` environment variable (if set)
3. `~/.cache/torch/hub/utmosv2-exported/` (default)

You can also pass `cache_dir` explicitly to `UTMOSv2Predictor`.

## Creating the Export (For Developers)

If you need to re-export the models (e.g., for a new UTMOSv2 version):

```bash
# Install with export dependencies
pip install -e ".[export]"

# Run export script
python scripts/export_model.py --output-dir models/

# Verify export
python scripts/verify_export.py test_audio.wav --model-dir models/
```

This will create:
- `utmosv2_ssl.pt` - TorchScript SSL encoder (~360 MB)
- `utmosv2_fusion.pt` - TorchScript fusion model (~65 MB)
- `utmosv2_config.json` - Preprocessing configuration

## Differences from Original UTMOSv2

| Feature | Original UTMOSv2 | utmosv2-exported |
|---------|------------------|------------------|
| Dependencies | transformers, torchvision | torch, torchaudio, librosa |
| Model format | PyTorch weights | TorchScript |
| SSL encoder | HuggingFace wav2vec2 | TorchScript traced |
| Installation size | ~2 GB | ~400 MB |

The inference results should be identical when using the same audio inputs. Small numerical differences (< 1e-5) may occur due to TorchScript tracing.

## Supported Audio Formats

Any format supported by `soundfile`:
- WAV
- FLAC
- OGG
- MP3 (if libsndfile compiled with MP3 support)

Audio is automatically:
- Converted to mono (if stereo)
- Resampled to 16kHz (if different sample rate)

## GPU Support

```python
# CUDA
predictor = UTMOSv2Predictor(device="cuda")

# Apple Silicon (MPS)
predictor = UTMOSv2Predictor(device="mps")

# Auto-detect
import torch
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
predictor = UTMOSv2Predictor(device=device)
```

## License

MIT License

## Credits

- Original UTMOSv2 model: [sarulab-speech/UTMOSv2](https://github.com/sarulab-speech/UTMOSv2)
- wav2vec2 model: [facebook/wav2vec2-base](https://huggingface.co/facebook/wav2vec2-base)

## Citation

If you use this package, please cite the original UTMOSv2 paper:

```bibtex
@inproceedings{utmosv2,
  title={UTMOSv2: A Strong and Highly Versatile Neural MOS Predictor},
  author={Baba, Yuuki and Saeki, Takaaki and Sakakibara, Kazuki and Nozaki, Ryo and Kubo, Yuki and Shinoda, Koichi},
  booktitle={Proceedings of Interspeech},
  year={2024}
}
```
